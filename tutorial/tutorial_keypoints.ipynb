{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "d3eef84f",
      "metadata": {
        "id": "d3eef84f"
      },
      "source": [
        "## Installation\n",
        "\n",
        "To run Jupyter notebook locally:\n",
        "\n",
        "```\n",
        "python3 -m pip install \"waymo_open_dataset_tf_2_6_0==1.4.3\"\n",
        "python3 -m pip install \"notebook\u003e=5.3\" \"ipywidgets\u003e=7.5\"\n",
        "python3 -m pip install --upgrade jupyter_http_over_ws\u003e=0.0.7 \u0026\u0026 \\\n",
        "jupyter serverextension enable --py jupyter_http_over_ws\n",
        "jupyter notebook\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "aSOsEurO9J_O",
      "metadata": {
        "id": "aSOsEurO9J_O"
      },
      "outputs": [],
      "source": [
        "from waymo_open_dataset.utils import range_image_utils\n",
        "from waymo_open_dataset.utils import transform_utils\n",
        "from waymo_open_dataset.utils import  frame_utils\n",
        "from waymo_open_dataset import dataset_pb2\n",
        "from waymo_open_dataset.protos import keypoint_pb2\n",
        "from waymo_open_dataset import label_pb2\n",
        "from waymo_open_dataset.utils import box_utils\n",
        "from waymo_open_dataset.utils import keypoint_utils"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "sa4Q3W1F5KJ9",
      "metadata": {
        "id": "sa4Q3W1F5KJ9"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "path = 'frame_with_keypoints.tfrecord'\n",
        "\n",
        "dataset = tf.data.TFRecordDataset(path, compression_type='')\n",
        "for data in dataset:\n",
        "    frame = dataset_pb2.Frame()\n",
        "    frame.ParseFromString(bytearray(data.numpy()))\n",
        "    break\n",
        "\n",
        "labels = keypoint_utils.group_object_labels(frame)\n",
        "print(f'Loaded {len(labels)} objects')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6mlBUrd9-g3k",
      "metadata": {
        "id": "6mlBUrd9-g3k"
      },
      "outputs": [],
      "source": [
        "#@title Auixiliary imports and utils\n",
        "\n",
        "import os\n",
        "import tensorflow.compat.v1 as tf\n",
        "import math\n",
        "import numpy as np\n",
        "from matplotlib import pylab as plt\n",
        "import plotly.graph_objects as go\n",
        "import itertools\n",
        "import PIL.Image\n",
        "import io\n",
        "import dataclasses\n",
        "\n",
        "tf.enable_eager_execution()\n",
        "\n",
        "def _imdecode(buf):\n",
        "  with io.BytesIO(buf) as fd:\n",
        "    pil = PIL.Image.open(fd)\n",
        "    return np.array(pil)\n",
        "\n",
        "def _imshow(ax, image_np):\n",
        "  ax.imshow(image_np)\n",
        "  ax.axis('off')\n",
        "  ax.set_autoscale_on(False)\n",
        "\n",
        "def _draw_laser_points(fig, points, color='gray', size=3):\n",
        "  fig.add_trace(go.Scatter3d(\n",
        "    mode='markers',\n",
        "    x=points[:, 0], y=points[:,1], z=points[:,2],\n",
        "    marker=dict(\n",
        "        color=color,\n",
        "        size=size\n",
        "    )\n",
        "  ))\n",
        "\n",
        "def _create_plotly_figure():\n",
        "  fig = go.Figure()\n",
        "  axis_settings = dict(\n",
        "          showgrid=False,\n",
        "          zeroline=False,\n",
        "          showline=False,\n",
        "          showbackground=False,\n",
        "          showaxeslabels=False,\n",
        "          showticklabels=False\n",
        "      )\n",
        "  fig.update_layout(\n",
        "    width=600,\n",
        "    height=600,\n",
        "    showlegend=False,\n",
        "    scene=dict(\n",
        "      aspectmode = 'data',  # force xyz has same scale,\n",
        "      xaxis=axis_settings,\n",
        "      yaxis=axis_settings,\n",
        "      zaxis=axis_settings,\n",
        "    ),\n",
        "  )\n",
        "  return fig"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "RiBlI9LK2fKs",
      "metadata": {
        "id": "RiBlI9LK2fKs"
      },
      "outputs": [],
      "source": [
        "#@title Select object and camera\n",
        "object_id = 'DQFLdFau_A8kTPOkDxfgJA'\n",
        "camera_name = dataset_pb2.CameraName.Name.FRONT_RIGHT\n",
        "\n",
        "camera_image_by_name = {i.name: i.image for i in frame.images}\n",
        "obj = labels[object_id]\n",
        "num_laser_points = len(obj.laser.keypoints.keypoint)\n",
        "num_camera_points = len(obj.camera[camera_name].keypoints.keypoint)\n",
        "\n",
        "print(f'Object {object_id} has')\n",
        "print(f'{num_laser_points} laser keypoints (short name | location | is_occluded):')\n",
        "for k in sorted(obj.laser.keypoints.keypoint, key=lambda k: k.type):\n",
        "  m = k.keypoint_3d.location_m\n",
        "  location_str = f'({m.x:.2f}, {m.y:.2f}, {m.z:.2f})'\n",
        "  print(f'{keypoint_utils.point_name(k.type)}\\t| {location_str:25} | {k.keypoint_3d.visibility.is_occluded}')\n",
        "print(f'\\na LaserKeypoint proto example:\\n\\n{obj.laser.keypoints.keypoint[0]}')\n",
        "\n",
        "print(f'{num_camera_points} camera keypoints (short name |  location | is_occluded):')\n",
        "for k in sorted(obj.camera[camera_name].keypoints.keypoint, key=lambda k: k.type):\n",
        "  px = k.keypoint_2d.location_px\n",
        "  location_str = f'({px.x:.0f}, {px.y:.0f})'\n",
        "  print(f'{keypoint_utils.point_name(k.type)}\\t| {location_str:13} | {k.keypoint_2d.visibility.is_occluded}')\n",
        "print(f'\\na CameraKeypoint proto example:\\n\\n{obj.camera[camera_name].keypoints.keypoint[0]}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "Zya-PvdW2fKt",
      "metadata": {
        "id": "Zya-PvdW2fKt"
      },
      "outputs": [],
      "source": [
        "#@title Show camera keypoints\n",
        "image_np = _imdecode(camera_image_by_name[camera_name])\n",
        "croped_image, cropped_camera_keypoints = keypoint_utils.crop_camera_keypoints(\n",
        "    image_np,\n",
        "    obj.camera[camera_name].keypoints.keypoint,\n",
        "    obj.camera[camera_name].box,\n",
        "    margin=0.3)\n",
        "camera_wireframe = keypoint_utils.build_camera_wireframe(cropped_camera_keypoints)\n",
        "\n",
        "keypoint_utils.OCCLUDED_BORDER_WIDTH = 3\n",
        "_, ax = plt.subplots(frameon=False, figsize=(5, 7))\n",
        "_imshow(ax, croped_image)\n",
        "keypoint_utils.draw_camera_wireframe(ax, camera_wireframe)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "Yc-erhA72fKy",
      "metadata": {
        "id": "Yc-erhA72fKy"
      },
      "outputs": [],
      "source": [
        "#@title Show laser keypoints\n",
        "\n",
        "# Select laser points inside pedestrian's bounding box\n",
        "(range_images, camera_projections, range_image_top_pose) = frame_utils.parse_range_image_and_camera_projection(frame)\n",
        "points, cp_points = frame_utils.convert_range_image_to_point_cloud(\n",
        "    frame,\n",
        "    range_images,\n",
        "    camera_projections,\n",
        "    range_image_top_pose)\n",
        "points_all = np.concatenate(points, axis=0)\n",
        "box = box_utils.box_to_tensor(obj.laser.box)[tf.newaxis, :]\n",
        "box_points = points_all[box_utils.is_within_box_3d(points_all, box)[:, 0]]\n",
        "print(f'{box_points.shape[0]} laser points selected.')\n",
        "\n",
        "# Visualize 3D scene\n",
        "laser_wireframe = keypoint_utils.build_laser_wireframe(obj.laser.keypoints.keypoint)\n",
        "fig = _create_plotly_figure()\n",
        "keypoint_utils.draw_laser_wireframe(fig, laser_wireframe)\n",
        "_draw_laser_points(fig, box_points)\n",
        "fig.show()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "Perception Dataset for Waymo Open Dataset: Human Keypoints (tutorial)",
      "private_outputs": true,
      "provenance": [
        {
          "file_id": "tutorial_keypoints.ipynb",
          "timestamp": 1643966716329
        }
      ]
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
